{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''<br>\n",
    "    @Author: v sanjay kumar<br>\n",
    "    @Date: 2024-09-08 04:00:30<br>\n",
    "    @Last Modified by: v sanjay kumar<br>\n",
    "    @Last Modified time: 2024-09-08 04:00:30.<br>\n",
    "    @Title :All files read and write problems<br>\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                          Read Csv File In Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .appName(\"Write CSV Example\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+-------+----------------------+\n",
      "|Year|Industry_aggregation_NZSIOC|Industry_code_NZSIOC|Industry_name_NZSIOC|             Units|Variable_code|       Variable_name|   Variable_category|  Value|Industry_code_ANZSIC06|\n",
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+-------+----------------------+\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H01|        Total income|Financial perform...| 930995|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H04|Sales, government...|Financial perform...| 821630|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H05|Interest, dividen...|Financial perform...|  84354|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H07|Non-operating income|Financial perform...|  25010|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H08|   Total expenditure|Financial perform...| 832964|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H09|Interest and dona...|Financial perform...|  55267|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H10|      Indirect taxes|Financial perform...|   7426|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H11|        Depreciation|Financial perform...|  30814|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H12|Salaries and wage...|Financial perform...| 147663|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H13|Redundancy and se...|Financial perform...|    269|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H14|Salaries and wage...|Financial perform...|   1639|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H19|Purchases and oth...|Financial perform...| 566979|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H20|Non-operating exp...|Financial perform...|  23176|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H21|      Opening stocks|Financial perform...|  80778|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H22|      Closing stocks|Financial perform...|  88197|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H23|Surplus before in...|Financial perform...| 105450|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H24|        Total assets|  Financial position|2831894|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H25|      Current assets|  Financial position| 861255|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H26|Fixed tangible as...|  Financial position| 681890|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H29|        Other assets|  Financial position|1288749|  ANZSIC06 division...|\n",
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df=spark.read.csv(r\"file:///C:\\Users\\sanju\\bridgelab_local files\\pyspark\\example1.csv\", header=True, inferSchema=True)\n",
    "    df.show()\n",
    "    spark.stop()\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                          write the csv file in pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = spark.read.csv(r\"file:///C:\\Users\\sanju\\bridgelab_local files\\pyspark\\example1.csv\", header=True, inferSchema=True)\n",
    "    \n",
    "    # Write the DataFrame as a CSV file\n",
    "    df.write.csv(\"file:///C:/Users/sanju/bridgelab_local files/pyspark/sanjay_output\", header=True)\n",
    "\n",
    "    # Show the DataFrame and print schema\n",
    "    df.show()\n",
    "    spark.stop()\n",
    "    df.printSchema()\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                             Read text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|    _c0|\n",
      "+-------+\n",
      "|twinkle|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Read the text file into a DataFrame\n",
    "    df = spark.read.csv(r\"file:///C:\\Users\\sanju\\OneDrive\\Documents\\Desktop\\poem.txt\")\n",
    "    # Show the DataFrame\n",
    "    df.show()\n",
    "\n",
    "    # Stop the SparkSession\n",
    "    spark.stop()\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                            Write the text file                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+------+----------------------+\n",
      "|Year|Industry_aggregation_NZSIOC|Industry_code_NZSIOC|Industry_name_NZSIOC|             Units|Variable_code|       Variable_name|   Variable_category| Value|Industry_code_ANZSIC06|\n",
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+------+----------------------+\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H01|        Total income|Financial perform...|930995|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H04|Sales, government...|Financial perform...|821630|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H05|Interest, dividen...|Financial perform...| 84354|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H07|Non-operating income|Financial perform...| 25010|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H08|   Total expenditure|Financial perform...|832964|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H09|Interest and dona...|Financial perform...| 55267|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H10|      Indirect taxes|Financial perform...|  7426|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H11|        Depreciation|Financial perform...| 30814|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H12|Salaries and wage...|Financial perform...|147663|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H13|Redundancy and se...|Financial perform...|   269|  ANZSIC06 division...|\n",
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+------+----------------------+\n",
      "\n",
      "RDD.saveAsTextFile() got an unexpected keyword argument 'mode'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\n",
    "    spark = SparkSession.builder.appName(\"Write DataFrame to Text File\").getOrCreate()\n",
    "    df = spark.read.csv(r\"file:///C:\\Users\\sanju\\bridgelab_local files\\pyspark\\new.csv\", header=True, inferSchema=True)\n",
    "    df.show()\n",
    "    # df.coalesce(1).write.format(\"text\").option(\"delimiter\", \",\").save(r\"file:///C:\\Users\\sanju\\bridgelab_local files\\pyspark\\new\", header=True, inferSchema=True)\n",
    "    df.rdd.map(lambda row: \"\\t\".join(map(str, row))).saveAsTextFile(r\"file:///C:\\Users\\sanju\\bridgelab_local files\\pyspark\\new\")\n",
    "    spark.stop\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                  Read json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+\n",
      "|age |id |name      |\n",
      "+----+---+----------+\n",
      "|30  |1  |John Doe  |\n",
      "|NULL|2  |Jane Smith|\n",
      "|25  |abc|Invalid ID|\n",
      "|28  |3  |Alice     |\n",
      "+----+---+----------+\n",
      "\n",
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_json_file(path):\n",
    "    try:\n",
    "        # Create a SparkSession\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"Read JSON from Local\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "        # Read the JSON file with the option to drop malformed records\n",
    "        df = spark.read.option(\"mode\", \"DROPMALFORMED\").json(path)\n",
    "        \n",
    "        # Cache the DataFrame to store parsed results in memory\n",
    "        df.cache()\n",
    "\n",
    "        # Show the DataFrame content\n",
    "        df.show(truncate=False)\n",
    "\n",
    "        # Optionally, show the schema of the DataFrame\n",
    "        df.printSchema()\n",
    "        spark.stop()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "json_file_path = r\"file:///C:/Users/sanju/Downloads/dwsample2-json.json\"\n",
    "\n",
    "\n",
    "read_json_file(json_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                            Write json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+------+----------------------+\n",
      "|Year|Industry_aggregation_NZSIOC|Industry_code_NZSIOC|Industry_name_NZSIOC|             Units|Variable_code|       Variable_name|   Variable_category| Value|Industry_code_ANZSIC06|\n",
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+------+----------------------+\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H01|        Total income|Financial perform...|930995|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H04|Sales, government...|Financial perform...|821630|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H05|Interest, dividen...|Financial perform...| 84354|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H07|Non-operating income|Financial perform...| 25010|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H08|   Total expenditure|Financial perform...|832964|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H09|Interest and dona...|Financial perform...| 55267|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H10|      Indirect taxes|Financial perform...|  7426|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H11|        Depreciation|Financial perform...| 30814|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H12|Salaries and wage...|Financial perform...|147663|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H13|Redundancy and se...|Financial perform...|   269|  ANZSIC06 division...|\n",
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    Df = spark.read.option(\"header\", \"true\").csv(\"file:///C:/Users/sanju/bridgelab_local files/pyspark/new.csv\")\n",
    "    Df.show()\n",
    "    output_path = \"file:///C:/Users/sanju/bridgelab_local files/pyspark/new.json\"\n",
    "    Df.write.json(output_path)\n",
    "    spark.stop()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
