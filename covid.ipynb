{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''<br>\n",
    "    @Author: v sanjay kumar<br>\n",
    "    @Date: 2024-09-06 04:00:30<br>\n",
    "    @Last Modified by: v sanjay kumar<br>\n",
    "    @Last Modified time: 2024-09-07 04:00:30.<br>\n",
    "    @Title :All covid problems in pyspark <br>\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import max, round\n",
    "from pyspark.sql.functions import coalesce, col\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.find death percentage  globaly  and localy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------global percentage ---------\n",
      "+--------------+----------------+\n",
      "|Country/Region|Death_percentage|\n",
      "+--------------+----------------+\n",
      "|          Chad|          8.5993|\n",
      "|      Paraguay|          1.0635|\n",
      "|        Russia|          1.3640|\n",
      "|         Yemen|         26.3575|\n",
      "|       Senegal|          1.5353|\n",
      "|    Cabo Verde|          1.0322|\n",
      "|        Sweden|          9.0267|\n",
      "|        Guyana|          7.0512|\n",
      "|       Eritrea|          0.0000|\n",
      "|   Philippines|          3.7305|\n",
      "|         Burma|          2.5369|\n",
      "|      Djibouti|          0.8956|\n",
      "|      Malaysia|          1.4792|\n",
      "|     Singapore|          0.0697|\n",
      "|          Fiji|          0.0000|\n",
      "|        Turkey|          2.6032|\n",
      "|        Malawi|          1.8290|\n",
      "|Western Sahara|          6.9922|\n",
      "|          Iraq|          3.9239|\n",
      "|       Germany|          4.1375|\n",
      "+--------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "----------local_percentage-----------\n",
      "+--------------------+----------------+\n",
      "|State/UnionTerritory|Death_percentage|\n",
      "+--------------------+----------------+\n",
      "|Andaman and Nicob...|            1.40|\n",
      "|      Andhra Pradesh|            0.75|\n",
      "|   Arunachal Pradesh|            0.37|\n",
      "|               Assam|            0.64|\n",
      "|               Bihar|            0.83|\n",
      "|           Bihar****|            1.32|\n",
      "|Cases being reass...|            0.00|\n",
      "|          Chandigarh|            1.36|\n",
      "|        Chhattisgarh|            1.26|\n",
      "|Dadra and Nagar H...|            0.04|\n",
      "|Dadra and Nagar H...|            0.05|\n",
      "|         Daman & Diu|            0.00|\n",
      "|               Delhi|            1.72|\n",
      "|                 Goa|            1.59|\n",
      "|             Gujarat|            1.55|\n",
      "|             Haryana|            1.12|\n",
      "|    Himachal Pradesh|            1.64|\n",
      "|   Himanchal Pradesh|            1.71|\n",
      "|   Jammu and Kashmir|            1.44|\n",
      "|           Jharkhand|            1.21|\n",
      "+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Find the global\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # Corrected file path\n",
    "    file_path = r\"file:///C:\\Users\\sanju\\OneDrive\\Documents\\dataset\\covid_19_clean_complete.csv\"\n",
    "    df_global = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "    file_path = r\"file:///C:\\Users\\sanju\\OneDrive\\Documents\\dataset\\Covid Problem\\covid_19_india.csv\"\n",
    "    df_local = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "    df_local.createOrReplaceTempView(\"covid_19_india\")\n",
    "    df_global.createOrReplaceTempView(\"country\")\n",
    "    global_result = spark.sql('''\n",
    "    SELECT `Country/Region`, \n",
    "           ROUND((SUM(Deaths) * 100.0 / SUM(Confirmed)), 4) AS Death_percentage\n",
    "    FROM country\n",
    "    GROUP BY `Country/Region`\n",
    "''')\n",
    "   \n",
    "    local_result=spark.sql('''\n",
    "    SELECT `State/UnionTerritory`, \n",
    "           ROUND((SUM(CAST(Deaths AS INT)) * 100.0) / SUM(CAST(Confirmed AS INT)), 2) AS Death_percentage\n",
    "    FROM covid_19_india\n",
    "    GROUP BY `State/UnionTerritory`\n",
    "    ORDER BY `State/UnionTerritory`\n",
    "''')\n",
    "    print(\"---------global percentage ---------\")\n",
    "    global_result.show()\n",
    "    print(\"----------local_percentage-----------\")\n",
    "    local_result.show()\n",
    "    spark.stop()\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. To find out the infected population percentage locally and globally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------globla infected percentage----------\n",
      "+--------------------+-----------+------------+----------------------------+\n",
      "|State/UnionTerritory|Total_Cases|Total_Active|Globally_Infected_percentage|\n",
      "+--------------------+-----------+------------+----------------------------+\n",
      "|            Nagaland|    5041742|        NULL|                        NULL|\n",
      "|           Karnataka|  485970693|       405.0|        8.333835884214524E-5|\n",
      "|              Odisha|  160130533|        23.0|        1.436328198570350...|\n",
      "|              Kerala|  458906023|      1091.0|        2.377393072480986E-4|\n",
      "|              Ladakh|    4054293|       162.0|         0.00399576448964098|\n",
      "|Dadra and Nagar H...|    1938632|        NULL|                        NULL|\n",
      "|          Tamil Nadu|  431928644|       138.0|        3.194972176932076...|\n",
      "|           Telengana|   69990668|       246.0|        3.514754281242179...|\n",
      "|        Chhattisgarh|  163776262|        25.0|        1.526472743650725...|\n",
      "|      Maharashtra***|    6229596|        NULL|                        NULL|\n",
      "|      Andhra Pradesh|  392432753|        81.0|        2.064047900711284...|\n",
      "|         Lakshadweep|     915784|        NULL|                        NULL|\n",
      "|      Madhya Pradesh|  135625265|       105.0|        7.741920356800777E-5|\n",
      "|              Punjab|   99949702|       231.0|        2.311162468498405...|\n",
      "|             Manipur|   12617943|         5.0|        3.962611021463641E-5|\n",
      "|         Daman & Diu|          2|        NULL|                        NULL|\n",
      "|Cases being reass...|     345565|        NULL|                        NULL|\n",
      "|                 Goa|   28240159|         9.0|        3.186950895000272E-5|\n",
      "|             Mizoram|    2984732|         4.0|        1.340153822855787...|\n",
      "|           Bihar****|    1430909|        NULL|                        NULL|\n",
      "+--------------------+-----------+------------+----------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "-----------local infected percentage-----------\n",
      "+--------------------+---------------+-----------+-----------------+\n",
      "|State/UnionTerritory|Total_Confirmed|Total_Cured| locally_Infected|\n",
      "+--------------------+---------------+-----------+-----------------+\n",
      "|            Nagaland|        5041742|    4519526| 10.3578485372714|\n",
      "|           Karnataka|      485970693|  441844360|  9.0800399356593|\n",
      "|              Odisha|      160130533|  150923455|  5.7497329381899|\n",
      "|              Kerala|      458906023|  420174235|  8.4400260747940|\n",
      "|              Ladakh|        4054293|    3758960|  7.2844513211058|\n",
      "|Dadra and Nagar H...|        1938632|    1841750|  4.9974414948273|\n",
      "|          Tamil Nadu|      431928644|  404095807|  6.4438507116004|\n",
      "|           Telengana|       69990668|   64666267|  7.6073013047968|\n",
      "|        Chhattisgarh|      163776262|  151609364|  7.4289752687114|\n",
      "|      Maharashtra***|        6229596|    6000911|  3.6709443116375|\n",
      "|      Andhra Pradesh|      392432753|  370426530|  5.6076417760166|\n",
      "|         Lakshadweep|         915784|     820925| 10.3582285779179|\n",
      "|      Madhya Pradesh|      135625265|  126724997|  6.5623967628745|\n",
      "|              Punjab|       99949702|   91458159|  8.4958162256452|\n",
      "|             Manipur|       12617943|   11230568| 10.9952549318062|\n",
      "|         Daman & Diu|              2|          0|100.0000000000000|\n",
      "|Cases being reass...|         345565|          0|100.0000000000000|\n",
      "|                 Goa|       28240159|   26027201|  7.8362094207756|\n",
      "|             Mizoram|        2984732|    2384602| 20.1066628427611|\n",
      "|           Bihar****|        1430909|    1402468|  1.9876176612209|\n",
      "+--------------------+---------------+-----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Start Spark session\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Find the infected population percentage\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # Load local dataset (India specific)\n",
    "    file_path_local = r\"file:///C:/Users/sanju/OneDrive/Documents/dataset/Covid Problem/covid_19_india.csv\"\n",
    "    df = spark.read.csv(file_path_local, header=True, inferSchema=True)\n",
    "    df.createOrReplaceTempView(\"country\")\n",
    "    global_infected=spark.sql('''\n",
    "    SELECT \n",
    "    `State/UnionTerritory`, \n",
    "        SUM(`Confirmed`) AS Total_Cases, \n",
    "        SUM(`ConfirmedIndianNational`) AS Total_Active,\n",
    "        (SUM(`ConfirmedIndianNational`) * 100.0 / SUM(`Confirmed`)) AS Globally_Infected_percentage\n",
    "    FROM \n",
    "        country\n",
    "    GROUP BY \n",
    "        `State/UnionTerritory` ''')\n",
    "    localy_infected=spark.sql('''\n",
    "    SELECT \n",
    "    `State/UnionTerritory`, \n",
    "    SUM(`Confirmed`) AS Total_Confirmed, \n",
    "    SUM(`Cured`) AS Total_Cured,\n",
    "    CASE \n",
    "        WHEN SUM(`Confirmed`) > 0 THEN \n",
    "            100 - (SUM(`Cured`) * 100.0 / SUM(`Confirmed`))\n",
    "        ELSE \n",
    "            NULL \n",
    "    END AS locally_Infected\n",
    "    FROM \n",
    "        country\n",
    "    GROUP BY \n",
    "        `State/UnionTerritory`\n",
    "''')\n",
    "    print(\"-----------globla infected percentage----------\")\n",
    "    global_infected.show()\n",
    "    print(\"-----------local infected percentage-----------\")\n",
    "    localy_infected.show()\n",
    "    spark.stop()\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.The countries with the highest infection rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country/Region: string (nullable = true)\n",
      " |-- Confirmed: integer (nullable = true)\n",
      " |-- Deaths: integer (nullable = true)\n",
      " |-- Recovered: integer (nullable = true)\n",
      " |-- Active: integer (nullable = true)\n",
      " |-- New cases: integer (nullable = true)\n",
      " |-- New deaths: integer (nullable = true)\n",
      " |-- New recovered: integer (nullable = true)\n",
      " |-- Deaths / 100 Cases: double (nullable = true)\n",
      " |-- Recovered / 100 Cases: double (nullable = true)\n",
      " |-- Deaths / 100 Recovered: string (nullable = true)\n",
      " |-- Confirmed last week: integer (nullable = true)\n",
      " |-- 1 week change: integer (nullable = true)\n",
      " |-- 1 week % increase: double (nullable = true)\n",
      " |-- WHO Region: string (nullable = true)\n",
      "\n",
      "+--------------+-------------------------+\n",
      "|Country/Region|Infection_Rate_Percentage|\n",
      "+--------------+-------------------------+\n",
      "|            US|                    26.03|\n",
      "|        Brazil|                    14.82|\n",
      "|         India|                     8.98|\n",
      "|        Russia|                     4.96|\n",
      "|  South Africa|                     2.75|\n",
      "|        Mexico|                      2.4|\n",
      "|          Peru|                     2.36|\n",
      "|         Chile|                     2.11|\n",
      "|United Kingdom|                     1.83|\n",
      "|          Iran|                     1.78|\n",
      "+--------------+-------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Find the global and local death percentage\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # Corrected file path\n",
    "    file_path = r\"file:///C:\\Users\\sanju\\OneDrive\\Documents\\dataset\\country_wise_latest.csv\"\n",
    "    \n",
    "\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "    df.printSchema()\n",
    "    # df.show()\n",
    "    df.createOrReplaceTempView(\"country\")\n",
    "    result = spark.sql('''\n",
    "    SELECT `Country/Region`, \n",
    "           ROUND((CAST(`Confirmed` AS FLOAT) / (SELECT SUM(CAST(`Confirmed` AS FLOAT)) FROM country)) * 100, 2) AS Infection_Rate_Percentage\n",
    "    FROM country\n",
    "    GROUP BY `Country/Region`, `Confirmed`\n",
    "    ORDER BY Infection_Rate_Percentage DESC\n",
    "''')\n",
    "\n",
    "    result.show(10)\n",
    "    \n",
    "    spark.stop()\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.The countries and continents with the highest death counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country/Region: string (nullable = true)\n",
      " |-- Confirmed: integer (nullable = true)\n",
      " |-- Deaths: integer (nullable = true)\n",
      " |-- Recovered: integer (nullable = true)\n",
      " |-- Active: integer (nullable = true)\n",
      " |-- New cases: integer (nullable = true)\n",
      " |-- New deaths: integer (nullable = true)\n",
      " |-- New recovered: integer (nullable = true)\n",
      " |-- Deaths / 100 Cases: double (nullable = true)\n",
      " |-- Recovered / 100 Cases: double (nullable = true)\n",
      " |-- Deaths / 100 Recovered: string (nullable = true)\n",
      " |-- Confirmed last week: integer (nullable = true)\n",
      " |-- 1 week change: integer (nullable = true)\n",
      " |-- 1 week % increase: double (nullable = true)\n",
      " |-- WHO Region: string (nullable = true)\n",
      "\n",
      "+--------------+--------------------+------+\n",
      "|Country/Region|          WHO Region|Deaths|\n",
      "+--------------+--------------------+------+\n",
      "|            US|            Americas|148011|\n",
      "|        Brazil|            Americas| 87618|\n",
      "|United Kingdom|              Europe| 45844|\n",
      "|        Mexico|            Americas| 44022|\n",
      "|         Italy|              Europe| 35112|\n",
      "|         India|     South-East Asia| 33408|\n",
      "|        France|              Europe| 30212|\n",
      "|         Spain|              Europe| 28432|\n",
      "|          Peru|            Americas| 18418|\n",
      "|          Iran|Eastern Mediterra...| 15912|\n",
      "+--------------+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Find hight death counts\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # Corrected file path\n",
    "    file_path = r\"file:///C:\\Users\\sanju\\OneDrive\\Documents\\dataset\\country_wise_latest.csv\"\n",
    "    \n",
    "\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "    df.printSchema()\n",
    "    # df.show()\n",
    "    df.createOrReplaceTempView(\"country\")\n",
    "    result = spark.sql('''\n",
    "        \n",
    "    SELECT `Country/Region`,`WHO Region`, Deaths\n",
    "    FROM country\n",
    "    ORDER BY Deaths DESC;\n",
    "    \n",
    "''')\n",
    "\n",
    "    result.show(10)\n",
    "    \n",
    "    spark.stop()\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Average number of deaths by day (Continents and Countries) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country/Region: string (nullable = true)\n",
      " |-- Continent: string (nullable = true)\n",
      " |-- Population: integer (nullable = true)\n",
      " |-- TotalCases: integer (nullable = true)\n",
      " |-- NewCases: integer (nullable = true)\n",
      " |-- TotalDeaths: integer (nullable = true)\n",
      " |-- NewDeaths: integer (nullable = true)\n",
      " |-- TotalRecovered: integer (nullable = true)\n",
      " |-- NewRecovered: integer (nullable = true)\n",
      " |-- ActiveCases: integer (nullable = true)\n",
      " |-- Serious,Critical: integer (nullable = true)\n",
      " |-- Tot Cases/1M pop: integer (nullable = true)\n",
      " |-- Deaths/1M pop: double (nullable = true)\n",
      " |-- TotalTests: integer (nullable = true)\n",
      " |-- Tests/1M pop: integer (nullable = true)\n",
      " |-- WHO Region: string (nullable = true)\n",
      "\n",
      "+--------------+-------------+----------+----------+--------+-----------+---------+--------------+------------+-----------+----------------+----------------+-------------+----------+------------+--------------------+\n",
      "|Country/Region|    Continent|Population|TotalCases|NewCases|TotalDeaths|NewDeaths|TotalRecovered|NewRecovered|ActiveCases|Serious,Critical|Tot Cases/1M pop|Deaths/1M pop|TotalTests|Tests/1M pop|          WHO Region|\n",
      "+--------------+-------------+----------+----------+--------+-----------+---------+--------------+------------+-----------+----------------+----------------+-------------+----------+------------+--------------------+\n",
      "|           USA|North America| 331198130|   5032179|    NULL|     162804|     NULL|       2576668|        NULL|    2292707|           18296|           15194|        492.0|  63139605|      190640|            Americas|\n",
      "|        Brazil|South America| 212710692|   2917562|    NULL|      98644|     NULL|       2047660|        NULL|     771258|            8318|           13716|        464.0|  13206188|       62085|            Americas|\n",
      "|         India|         Asia|1381344997|   2025409|    NULL|      41638|     NULL|       1377384|        NULL|     606387|            8944|            1466|         30.0|  22149351|       16035|      South-EastAsia|\n",
      "|        Russia|       Europe| 145940924|    871894|    NULL|      14606|     NULL|        676357|        NULL|     180931|            2300|            5974|        100.0|  29716907|      203623|              Europe|\n",
      "|  South Africa|       Africa|  59381566|    538184|    NULL|       9604|     NULL|        387316|        NULL|     141264|             539|            9063|        162.0|   3149807|       53044|              Africa|\n",
      "|        Mexico|North America| 129066160|    462690|    6590|      50517|      819|        308848|        4140|     103325|            3987|            3585|        391.0|   1056915|        8189|            Americas|\n",
      "|          Peru|South America|  33016319|    455409|    NULL|      20424|     NULL|        310337|        NULL|     124648|            1426|           13793|        619.0|   2493429|       75521|            Americas|\n",
      "|         Chile|South America|  19132514|    366671|    NULL|       9889|     NULL|        340168|        NULL|      16614|            1358|           19165|        517.0|   1760615|       92022|            Americas|\n",
      "|      Colombia|South America|  50936262|    357710|    NULL|      11939|     NULL|        192355|        NULL|     153416|            1493|            7023|        234.0|   1801835|       35374|            Americas|\n",
      "|         Spain|       Europe|  46756648|    354530|    NULL|      28500|     NULL|          NULL|        NULL|       NULL|             617|            7582|        610.0|   7064329|      151087|              Europe|\n",
      "|          Iran|         Asia|  84097623|    320117|    NULL|      17976|     NULL|        277463|        NULL|      24678|            4156|            3806|        214.0|   2612763|       31068|EasternMediterranean|\n",
      "|            UK|       Europe|  67922029|    308134|    NULL|      46413|     NULL|          NULL|        NULL|       NULL|              73|            4537|        683.0|  17515234|      257873|              Europe|\n",
      "|  Saudi Arabia|         Asia|  34865919|    284226|    NULL|       3055|     NULL|        247089|        NULL|      34082|            1915|            8152|         88.0|   3635705|      104277|EasternMediterranean|\n",
      "|      Pakistan|         Asia| 221295851|    281863|    NULL|       6035|     NULL|        256058|        NULL|      19770|             809|            1274|         27.0|   2058872|        9304|EasternMediterranean|\n",
      "|    Bangladesh|         Asia| 164851401|    249651|    NULL|       3306|     NULL|        143824|        NULL|     102521|            NULL|            1514|         20.0|   1225124|        7432|      South-EastAsia|\n",
      "|         Italy|       Europe|  60452568|    249204|    NULL|      35187|     NULL|        201323|        NULL|      12694|              42|            4122|        582.0|   7099713|      117443|              Europe|\n",
      "|        Turkey|         Asia|  84428331|    237265|    NULL|       5798|     NULL|        220546|        NULL|      10921|             580|            2810|         69.0|   5081802|       60191|              Europe|\n",
      "|     Argentina|South America|  45236884|    228195|    NULL|       4251|     NULL|         99852|        NULL|     124092|            1150|            5044|         94.0|    794544|       17564|            Americas|\n",
      "|       Germany|       Europe|  83811260|    215210|    NULL|       9252|     NULL|        196200|        NULL|       9758|             236|            2568|        110.0|   8586648|      102452|              Europe|\n",
      "|        France|       Europe|  65288306|    195633|    NULL|      30312|     NULL|         82460|        NULL|      82861|             384|            2996|        464.0|   3992206|       61147|              Europe|\n",
      "+--------------+-------------+----------+----------+--------+-----------+---------+--------------+------------+-----------+----------------+----------------+-------------+----------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "[PARSE_SYNTAX_ERROR] Syntax error at or near '#'.(line 2, pos 4)\n",
      "\n",
      "== SQL ==\n",
      "\n",
      "    # SELECT\n",
      "----^^^\n",
      "    #     `Country/Region`,\n",
      "    #     Population,\n",
      "    #     TotalCases,\n",
      "    #     CASE \n",
      "    #         WHEN Population = 0 THEN NULL\n",
      "    #         ELSE CAST(TotalCases AS FLOAT) / CAST(Population AS FLOAT)\n",
      "    #     END AS CasesPerPopulation\n",
      "    # FROM\n",
      "    #     worldometer_data\n",
      "    # WHERE\n",
      "    #     Population RLIKE '^[0-9]+$'\n",
      "    #     AND TotalCases RLIKE '^[0-9]+$'\n",
      "    #     AND CAST(Population AS FLOAT) <> 0\n",
      "    # ORDER BY\n",
      "    #     CasesPerPopulation DESC \n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Avarage number of deaths\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # Corrected file path\n",
    "    file_path = r\"file:///C:\\Users\\sanju\\OneDrive\\Documents\\dataset\\worldometer_data.csv\"\n",
    "    \n",
    "\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "    df.printSchema()\n",
    "    df.createOrReplaceTempView(\"worldometer_data\")\n",
    "    result = spark.sql('''\n",
    "    SELECT\n",
    "        `Country/Region`,\n",
    "        Population,\n",
    "        TotalCases,\n",
    "        CASE \n",
    "            WHEN Population = 0 THEN NULL\n",
    "            ELSE CAST(TotalCases AS FLOAT) / CAST(Population AS FLOAT)\n",
    "        END AS CasesPerPopulation\n",
    "    FROM\n",
    "        worldometer_data\n",
    "    WHERE\n",
    "        Population RLIKE '^[0-9]+$'\n",
    "        AND TotalCases RLIKE '^[0-9]+$'\n",
    "        AND CAST(Population AS FLOAT) <> 0\n",
    "    ORDER BY\n",
    "        CasesPerPopulation DESC ''')\n",
    "    result.show(10)\n",
    "\n",
    "    spark.stop()\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 6.Average of cases divided by the number of population of each country (TOP 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country/Region: string (nullable = true)\n",
      " |-- Continent: string (nullable = true)\n",
      " |-- Population: integer (nullable = true)\n",
      " |-- TotalCases: integer (nullable = true)\n",
      " |-- NewCases: integer (nullable = true)\n",
      " |-- TotalDeaths: integer (nullable = true)\n",
      " |-- NewDeaths: integer (nullable = true)\n",
      " |-- TotalRecovered: integer (nullable = true)\n",
      " |-- NewRecovered: integer (nullable = true)\n",
      " |-- ActiveCases: integer (nullable = true)\n",
      " |-- Serious,Critical: integer (nullable = true)\n",
      " |-- Tot Cases/1M pop: integer (nullable = true)\n",
      " |-- Deaths/1M pop: double (nullable = true)\n",
      " |-- TotalTests: integer (nullable = true)\n",
      " |-- Tests/1M pop: integer (nullable = true)\n",
      " |-- WHO Region: string (nullable = true)\n",
      "\n",
      "+--------------+------------+----------+--------------------+\n",
      "|Country/Region|  Population|TotalCases|  CasesPerPopulation|\n",
      "+--------------+------------+----------+--------------------+\n",
      "|         Qatar|   2807805.0|  112092.0|0.039921575750452756|\n",
      "| French Guiana|    299385.0|    8127.0|0.027145648579588157|\n",
      "|       Bahrain|   1706669.0|   42889.0| 0.02513023907975126|\n",
      "|    San Marino|     33938.0|     699.0|0.020596381637102954|\n",
      "|         Chile| 1.9132514E7|  366671.0|0.019164810228284687|\n",
      "|        Panama|   4321282.0|   71418.0| 0.01652703989232825|\n",
      "|        Kuwait|   4276658.0|   70045.0|0.016378443167538764|\n",
      "|          Oman|   5118446.0|   80713.0|0.015769043963734304|\n",
      "|           USA|3.31198144E8| 5032179.0|0.015193862960518527|\n",
      "|  Vatican City|       801.0|      12.0|  0.0149812734082397|\n",
      "+--------------+------------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Avarage of cases divided by the population\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # Corrected file path\n",
    "    file_path = r\"file:///C:\\Users\\sanju\\OneDrive\\Documents\\dataset\\worldometer_data.csv\"\n",
    "    \n",
    "\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "    df.printSchema()\n",
    "    df.createOrReplaceTempView(\"worldometer_data\")\n",
    "    result=spark.sql('''\n",
    "    SELECT `Country/Region`,\n",
    "           CAST(Population AS FLOAT) AS Population,\n",
    "           CAST(TotalCases AS FLOAT) AS TotalCases,\n",
    "           CASE \n",
    "               WHEN CAST(Population AS FLOAT) = 0 THEN NULL\n",
    "               ELSE CAST(TotalCases AS FLOAT) / CAST(Population AS FLOAT)\n",
    "           END AS CasesPerPopulation\n",
    "    FROM worldometer_data\n",
    "    WHERE Population RLIKE '^[0-9]+$'\n",
    "      AND TotalCases RLIKE '^[0-9]+$'\n",
    "      AND CAST(Population AS FLOAT) <> 0\n",
    "    ORDER BY CasesPerPopulation DESC\n",
    "''')\n",
    "    result.show(10)\n",
    "\n",
    "    spark.stop()\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
